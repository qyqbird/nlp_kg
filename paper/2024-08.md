# Scalable Diffusion Models with Transformers
探索了一种基于 Transformer 架构的新型扩散模型，称为 Diffusion Transformers（DiTs）。
使用 Transformer 架构替代了传统的 U-Net 骨干网络，用于图像的潜在扩散模型 。
性能提升：通过增加Transformer的深度、宽度或输入tokens的数量，DiTs在图像生成任务上展现出了比之前所有扩散模型更优秀的表现，尤其在高质量图像生成方面 。

可扩展性分析：研究了网络复杂度（以 Gflops 度量）与样本质量（以 FID 度量）之间的强相关性，发现随着模型复杂度的增加，样本质量得到提升 。
实验结果：DiTs 在类条件 ImageNet 512x512 和 256x256 基准测试中优于所有先前的扩散模型，特别是在 256x256 分辨率上达到了 2.27 的最先进 FID 。
设计空间：论文还探讨了 DiT 设计空间，包括不同的 Transformer 块设计，例如上下文条件、交叉注意力块、自适应层归一化（adaLN）块和 adaLN-Zero 块，并对这些设计进行了评估 。
潜在扩散模型（LDM）：DiT 应用于潜在空间，使用预训练的变分自编码器（VAE）来压缩图像到潜在表示，然后在这个空间上训练扩散模型，有效地提高了计算效率 。
计算效率：DiT-XL/2 模型在计算效率上优于基于 U-Net 的扩散模型，如 ADM 和 LDM，同时实现了更低的 FID，展示了 Transformer 架构在图像生成任务中的潜力 。
未来方向：论文提出，未来的工作可以继续扩展 DiTs 到更大的模型和更多的 tokens，并且 DiT 也可以作为文本到图像模型的替代骨干进行探索 。
这篇论文在图像生成领域提供了一种新的视角，通过 Transformer 架构改进扩散模型，不仅推动了模型性能的边界，也为未来的研究提供了新的方向。

# SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis
SDXL模型的一些关键特点包括：
*   使用了3倍大的UNet backbone，增加了更多的attention块和更大的cross-attention，因为使用了2个text encoder。
*   引入了两个额外的条件条件注入，无需额外监督，可以提高多纵横比上的微调效果。
*   通过将图像的原始尺寸作为条件嵌入到U-Net模型中，让模型学习到图像分辨率参数，提高了数据利用效率。
*   将训练过程中裁剪的坐标作为额外的条件注入到UNet中，解决了图像裁剪导致的缺失问题。
*   通过多尺度微调，让模型学习到了多尺度生成，避免了过量裁剪图像对模型的不利影响 
*	low local quality: 通过引入一个在高清大图是refinement的模型


# Kolors: Effective Training of Diffusion Model for Photorealistic Text-to-Image Synthesis
快手可图。特点支持中英文，很好的写实主义
1. GLM文本encoder替换了T5或者CLIP。多模态CogVLM recaption 显著提升了复杂的语义理解能力
2. 2阶段学习，先学习concept，接着提升图像质量（高清大图+不同的scheduler）。
3. 提出了category-balanced benchmark
知识点
1. 高清大图，inadequte noise。1000步的前向随机过程后，不完全是白噪声，仍然保留有低频信息
2. 相对英文，中文字符的广泛性，及复杂的内涵，使得rendering相对更难。