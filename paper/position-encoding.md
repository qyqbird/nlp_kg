# LM-Infinite LM零样本极限长度推广
NAACL-2024 Best Paper. 的确很精彩
1. 无限长度，注意力logits 必须爆炸，才能保证attention
2. 如果logits abound, 那么logits的熵爆炸
3. 初始位置的前几个字符，其实是带上了位置信息，在embedding space中，所在的位置是完全不一样的。

# LM-Steer: 词向量是语言模型的方向盘
ACL-2024 Best Paper
Do word embeddings Embed in LM?

