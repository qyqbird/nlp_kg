卷积神经网络的核心是卷积核，用于在输入数据上滑动并提取特征。一维卷积适用于一维序列数据，如语音和文本，二维卷积则常用于图像数据，捕捉空间信息。卷积核的权重通过反向传播优化，一维和二维卷积可结合用于复杂任务，如文本特征提取。
# 理解一维卷积
https://www.cnblogs.com/szxspark/p/8445406.html
图像二维卷积很好理解，卷积核size*size*输入通道；对应在NLP，比如word embedding 16, 文本长度8，那么对应的一维卷积核size*16, 这里的通道数就是embedding size.
通过改变输出通道，来使得输出维度的变化，也就是降维和升维
1维卷积 因为是1*1 ，那么它的感受野就是 一个像素， 所以它没法感受到它旁边的像素,有一个求和的过程，也就是将不同channel的卷积结果进行求和


